{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet GPT - Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code used to train a small language model using PyTorch from scratch. The model is inspired by the GPT architecture.\n",
    "\n",
    "\n",
    "#### Hardware\n",
    "- RTX3060 12GB VRAM\n",
    "- AMD Ryzen 7 5800X 8-Core\n",
    "- 32GB RAM\n",
    "- Ubuntu 22.04 LTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "CACHE_DIR = \"/media/rob/RobsDisk/cache_data_llm\"\n",
    "os.environ['HF_HOME'] = CACHE_DIR\n",
    "os.environ['HF_DATASETS_CACHE'] = os.path.join(CACHE_DIR, \"datasets\")\n",
    "os.environ['HF_METRICS_CACHE'] = os.path.join(CACHE_DIR, \"metrics\")\n",
    "os.environ['HF_MODULES_CACHE'] = os.path.join(CACHE_DIR, \"modules\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rob/micromamba/envs/mlenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import random, math\n",
    "\n",
    "from datasets import load_dataset,concatenate_datasets\n",
    "import tiktoken\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "### Common knowledge datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### English Wikipedia crawled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Wikipedia dataset loaded.\n",
      "dataset size in gb: 18.812774107791483\n",
      "Number of entries: 6407814\n",
      "--------------------------------------------------\n",
      "Example entry:\n",
      "Kamel Habri (; born March 5, 1976, in Tlemcen) is a retired Algerian international football player. He spent the majority of his career with his hometown club of WA Tlemcen. He also had 7 caps for the Algeria National Team and was a member of the team at the 1998 African Cup of Nations in Burkina Faso.\n",
      "\n",
      "Club career\n",
      " 1994-2000 WA Tlemcen \n",
      " 2000-2003 JSM Béjaïa \n",
      " 2003-2006 JS Kabylie \n",
      " 2006-2008 JSM Béjaïa \n",
      " 2008-2011 WA Tlemcen\n",
      "\n",
      "Honours\n",
      " Won the Arab Champions League once with WA Tlemcen in 1998\n",
      " Won the Algerian Cup once with WA Tlemcen in 1998\n",
      " Won the Algerian League once with JS Kabylie in 2004\n",
      " Played in the 1998 African Cup of Nations in Burkina Faso\n",
      " Has 7 caps for the Algerian National Team\n",
      "\n",
      "References\n",
      "\n",
      "1976 births\n",
      "1998 African Cup of Nations players\n",
      "Algerian men's footballers\n",
      "Algeria men's international footballers\n",
      "Algerian Ligue Professionnelle 1 players\n",
      "JS Kabylie players\n",
      "JSM Béjaïa players\n",
      "Living people\n",
      "People from Tlemcen\n",
      "WA Tlemcen players\n",
      "Algeria men's under-23 international footballers\n",
      "Men's association football defenders\n",
      "21st-century Algerian people\n"
     ]
    }
   ],
   "source": [
    "# English Wikipedia crawled dataset\n",
    "# path to store the dataset cache: /Volumes/RobertsDisk\n",
    "wiki_en = load_dataset(\"wikimedia/wikipedia\", \"20231101.en\", split='train', cache_dir=CACHE_DIR) \n",
    "print(\"English Wikipedia dataset loaded.\")\n",
    "print(\"dataset size in gb:\", wiki_en.dataset_size / (1024**3))\n",
    "print(\"Number of entries:\", len(wiki_en))\n",
    "print(\"-\"*50)\n",
    "print(\"Example entry:\")\n",
    "print(wiki_en[random.randint(0, len(wiki_en)-1)]['text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple stories dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple stories dataset loaded.\n",
      "dataset size in mb: 3030.012650489807\n",
      "Number of entries: 2115696\n",
      "--------------------------------------------------\n",
      "Example entry:\n",
      "Beneath the waves, a girl named Lily swam happily. She loved the ocean and all the colorful fish. One day, she found an old treasure chest on the sea floor. Curious, she opened it. Inside was a beautiful necklace that glowed with a bright light. \"What is this?\" she wondered.\n",
      "\n",
      "Suddenly, a figure burst from the water. It was Aqua Knight, a hero of the sea! \"That necklace holds the power of the ocean,\" he explained. \"But beware, for the Dark Tide seeks it for evil.\" Just as he spoke, a shadow appeared. It was the anti-hero, the Deep Whisper. He was known for stealing treasures and causing chaos.\n",
      "\n",
      "\"Hand over the necklace!\" Deep Whisper shouted. Aqua Knight stood firm. \"You will not take it!\" he declared. Lily felt a mix of fear and bravery. She wanted to protect the treasure and help Aqua Knight. \"We must outsmart him!\" she said, her mind racing.\n",
      "\n",
      "Lily had an idea. \"What if we create a whirlpool?\" she suggested. Aqua Knight nodded, understanding her plan. They swam together, creating circles in the water. The waves began to swirl, and soon a powerful whirlpool formed. Deep Whisper looked surprised as he struggled to stay afloat.\n",
      "\n",
      "As the whirlpool grew stronger, Lily focused on the necklace. \"Let's use its power!\" she shouted. The necklace glowed brighter, and the whirlpool pulled Deep Whisper into it. With one final push, they sent him far away from the treasure. \n",
      "\n",
      "Once the danger was gone, Aqua Knight turned to Lily. \"You were clever!\" he praised. \"Together, we protected the ocean.\" Lily felt proud. They decided to use the necklace to keep the sea safe from harm. They swam off, ready for more adventures in the deep blue.\n",
      "\n",
      "In the days that followed, Lily and Aqua Knight became the protectors of the ocean. They learned that creativity and teamwork could conquer even the darkest villains. The ocean sparkled as they set off on new quests together, filled with excitement and hope.\n"
     ]
    }
   ],
   "source": [
    "# Simple stories dataset\n",
    "stories = load_dataset(\"SimpleStories/SimpleStories\", split='train', cache_dir=CACHE_DIR)\n",
    "print(\"Simple stories dataset loaded.\")\n",
    "print(\"dataset size in mb:\", stories.dataset_size / (1024**2))\n",
    "print(\"Number of entries:\", len(stories))\n",
    "print(\"-\"*50)\n",
    "print(\"Example entry:\")\n",
    "print(stories[random.randint(0, len(stories)-1)]['story'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FineWeb-Edu dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineWeb-Edu is ready.\n",
      "dataset size in gb: 45.730818568728864\n",
      "Number of entries: 9672101\n",
      "--------------------------------------------------\n",
      "Example entry:\n",
      "Deb thru-hiked the Appalachian Trail and is a Search & Rescue volunteer and writer living in Flagstaff, AZ.\n",
      "See Geology at its Best in the Paria Canyon-Vermilion Cliffs Wilderness\n",
      "Until a friend invited me on a hiking trip in northern Arizona and southern Utah, I'd not heard of the Wave. But I realized when we arrived that I had seen photos of this amazing geological formation, now an internationally known and very popular wilderness destination. Which is why daily visitation to the Wave has been limited by the Bureau of Land Management, to prevent excessive damage, crowding, and overuse of the area.\n",
      "If you're willing to take your chances with the permit process, which I'll describe below, and can hike six, mostly easy to moderately difficult (round-trip) miles in desert terrain, I highly recommend a visit to the Wave.\n",
      "Here, I'll show you photos from one of my own hikes to the Wave (I've now been there three times), describe the route, the terrain, and a little of the geological history of the area, and tell you—and show you—how to get there once you've obtained your Wave permit.\n",
      "Have You Been To the Wave in North Coyote Buttes? - A Visitor Poll\n",
      "What Forces Created the Wave?\n",
      "According to Wikipedia, the Wave is composed of Jurassic-age Navajo sandstone, approximately 190 million years old. Scientists say the ancient sand dunes turned into hard, compacted rock over the ages, calcifying in vertical and horizontal layers. Further erosion by wind and rain created the spectacular landscape we see today.\n",
      "You can read more about the unique geological characteristics of the Wave on Geology.com.\n",
      "Hiking to the Wave: A Pictorial Guide\n",
      "You start from the Wire Pass trailhead on House Rock Valley Road....C'mon, let's go!\n",
      "You'll begin your hike to the Wave by walking up a wash. If you continued along this wash, it would eventually lead you into Buckskin Gulch, the world's longest slot canyon, but to go to the Wave you'll turn off to the right—south/southeast—before then.\n",
      "If you see a narrow slot up ahead, you've gone too far.\n",
      "Of course, washes aren't always dry, so check the weather forecast (you can ask at the Ranger Station) before you begin your hike to the Wave. You don't want to be in that wash when it's running.\n",
      "Coordinates of the Wave:\n",
      "- Latitude 36° 59' 45.84\" N\n",
      "- Longitude 112° 0' 21.9\" W\n",
      "You can view a topographic map of Coyote Buttes, Arizona, including the Wave, at TopoQuest.com.\n",
      "The Trail Towards the Wave Departs From the Wash\n",
      "But you're not on a trail for long.\n",
      "After following the wash for less than a mile, you'll see a sign post on your right: \"Coyote Buttes.\" (NOTE: There's still a sign there, but it's been changed to a white sign on a wooden post, and it's on the right side of the trail, not the left as pictured here.)\n",
      "All hikers need a permit to enter this area, whether or not they're headed for the Wave or some other destination. And the Wave requires a specific permit, which should be displayed on the backpack of one person in each party.\n",
      "When you first turn off from the wash, you'll climb a short but steep, sandy hill, which will get your heart rate going. This and the final climb up a sand dune just before the Wave are the most difficult parts of the hike.\n",
      "Due to a number of people getting lost in the area, the Bureau of Land Management has amended the material they give out to Wave permit-holders to include GPS coordinates of various points along the route and a photographic map of features to keep an eye out for.\n",
      "If you pay attention to the directions and the terrain, you should have no problem finding the Wave, although, we did still run into people out there who seemed confused.\n",
      "A View of the Landscape En Route to the Wave\n",
      "Some folks say it looks like another planet.\n",
      "This stark, other-worldly, and amazingly beautiful land gets extremely hot in the summer, with temperatures often reaching above 100 degrees Fahrenheit by midday. So, if you're hiking to the Wave in June, July or August, be sure to start very early (before sunrise would be best), carry plenty of water (a gallon per person for the day, I'd say), and wear a wide-brimmed hat. And don't forget some snacks—sugary and salty—to keep your electrolytes and energy up.\n",
      "Forgive me if it goes without saying, but just in case.... cellphones won't work out here, so be prepared, because you can't ring or text for assistance.\n",
      "The Route: Sand and Slickrock\n",
      "After a short stretch on sandy trail, you'll come to a large area of slickrock, which, when dry, offers very good footing.\n",
      "Now you'll no longer be guided by trail but rather by terrain features and, here and there, small cairns (man-made piles of rocks). I found these cairns, which are often made up of no more than two or three small rocks, easy to miss and sometimes a bit confusing, but you'll probably spot most of them if you keep a careful eye out. They really aren't necessary, though, to find your way to the Wave. (NOTE: The BLM has been removing these confusing cairns.)\n",
      "Head for the Twin Buttes\n",
      "The BLM instructions will point you to the right of two large ... well, I call them rock lumps, but they're officially called the \"Twin Buttes.\" They should be pretty easy to identify from the photos on your handout. Be careful, though; there are other double \"rock lumps\" around that could fool you.\n",
      "Still, even if you stray in this area, another major feature in the distance will draw you into the Wave.\n",
      "Navigating to the Wave Shouldn't Be Difficult\n",
      "...if you follow directions and pay attention to the map and terrain.\n",
      "Here, my friend Sueanne walks to the right of the Twin Buttes. The buttes can be passed on the left, but it's easier to walk up the slickrock bowl and go around to the right.\n",
      "Half a mile past the Twin Buttes, you'll come to a wash. If you look across the wash, you'll see the multicolored domes on the opposite side. These and the sandstone formations to the right are where the Wave is located.\n",
      "Finding The Wave\n",
      "Head for the crack in the rock. See it in the distance, just to the left of center in the photo?\n",
      "The Wave is located below that dark crack -- aptly known as \"the Black Crack\" -- in the distance (pictured here just to the left of center). Just make your way cross-country towards that point.\n",
      "The Ascent Before the Wave\n",
      "Trudge up this sand dune to reach your destination.\n",
      "This is the most difficult part of the hike to The Wave -- and it's a bit steeper and longer than it looks in this photo -- but you'll be well rewarded at the top.\n",
      "So, do a slow, choppy trudge or pick up steam and motor your way up the last stretch of sand, whatever suits you, and you'll be at your destination shortly.\n",
      "Arriving at the Wave: A Hidden Gem\n",
      "Take your time. Explore the nooks and crannies. Check out the details. Listen to the silence and imagine this place thousands and millions of years ago.\n",
      "Close-ups of The Wave—The Ultimate \"Rock Art\"\n",
      "Natural Design—Pay Attention to the Amazing Details\n",
      "Do you see the forms of other things in these designs by nature?\n",
      "These Designs Look Like Waves, too, Don't They?\n",
      "The Wave 2: A Short Walk Beyond the Wave\n",
      "A third of a mile west of the Wave is another amazing formation, this one with lighter pastel colors. Just continue along on the \"shelf\" at the same level as the Wave, and you'll find it.\n",
      "The Wave Is Hidden in This Amazing Landscape—And so Am I!\n",
      "A special treat after a rainstorm: Small pools, which can remain for several days, often contain a large number of tadpoles and fairy shrimp.\n",
      "That's the True Color of the Sky\n",
      "Video: Images from a Hike to the World-Famous Wave\n",
      "The images in this video were taken by Anna Malkowicz, who was visiting from Poland.\n",
      "Getting a Permit for the Hike\n",
      "This isn't the fun part of the Wave experience, but it is required.\n",
      "My friend and I got lucky. Ours was the third application drawn that morning, as more than 50 people waited at the Ranger Station to find out if they'd get a permit for the Wave for the following day. There were spots remaining for only two more people, and the remaining parties consisted of three and four people.\n",
      "The Permit Process Explained:\n",
      "Only 20 people are allowed into the Wave each day, with a maximum group size of six.\n",
      "Ten spots are reserved for the in-person permit lottery at the Ranger Station, beginning at 9 am each morning, and ten other slots are doled out by the online lottery system. You would need to arrive at the Ranger Station early to fill out the application and be entered into the drawing. The permit is for the NEXT day, not that same day it's drawn.\n",
      "Again, day-use permits for The Wave and North Coyote Buttes are available online and as walk-in permits at the Grand Staircase-Escalante National Monument Visitor Center in Kanab, Utah (Phone: 435-826-5499), the day before you want to hike. (You can also obtain permits for South Coyote Buttes, also a beautiful area, and those permits are easier to get.)\n",
      "For the online permit lottery, you have to pay a $5 nonrefundable application fee, and you can choose up to three dates per application. If you win a permit, you will be given just one of the three days. With the in-person lottery, you pay only if you receive a permit. The permits are $7 per person.\n",
      "Online permits for the Wave may be obtained up to four months in advance, and you have an entire month to apply.\n",
      "If you enter the lottery for the Wave and Coyote Buttes North, attempting to obtain a permit for the months of April, May, September, or October, the odds are about 10%. For other months (in the off-season), the chances are better.\n",
      "Visit the BLM website for more information on how to obtain a permit for the Wave.\n",
      "Be aware that the area is patrolled by rangers, and fines will be issued to those without permits. A copy of the permit will also need to be displayed on the dashboard of your vehicle.\n",
      "Take a Look at the In-Person Permit Lottery for the Wave\n",
      "This took place at the Paria Ranger Station, but you can no longer get the permits here. You'll have to go to the Kanab Ranger Station. This is what you can expect, though....\n",
      "Directions To the Wave Trailhead on House Rock Valley Road\n",
      "The Wave is located in the North Coyote Buttes area south of US Highway 89 between Page, Arizona, and Kanab, Utah. The hike begins at the Wire Pass Trailhead on unpaved House Rock Valley Road in the Paria Canyon-Vermillion Cliffs Wilderness.\n",
      "When House Rock Valley Road is wet, it can become impassable. During dry conditions, however, a two-wheel drive vehicle is sufficient, though high clearance would be preferable.\n",
      "Getting to the Trailhead\n",
      "The turnoff from US 89 onto House Rock Valley Road is not signed, but it's located between mile markers 25 and 26 about 40 miles east of Kanab, Utah and 34 miles west of Page. This turnoff is 4 miles west of the Paria Ranger Station.\n",
      "About 4.2 miles south of US 89 on House Rock Valley Road, you pass the Buckskin Trailhead on your left. Then, 3.7 miles further is the Wire Pass Trailhead with a large parking area and restrooms. The parking area is on the right (heading northbound), but the actual trailhead is on the left.\n",
      "The trailhead is located in Utah, while the Wave itself is actually in Arizona.\n",
      "Trailhead coordinates: 37 degrees 1.19'N / 112 degrees 1.48'W\n",
      "An Article From The Los Angeles Times\n",
      "- Arizona's Wave rock formation a stone-cold stunner\n",
      "So there I was, standing with about 30 other hikers in boots and backpacks, jammed into a room no bigger than a double-wide in a one-story beige government building in a destitute moonscape....\n",
      "More Information About The Wave—And Other Places To Visit In Coyote Buttes\n",
      "- The Wave: Photography by Rick Decker\n",
      "This site is dedicated not only to The Wave but also to photographer and guide Jackson Bridges, who lived for many years in Page, Arizona, and passed in July 2019.\n",
      "- The Wave--Coyote Buttes | Utah.com\n",
      "The Wave has become a popular attraction in the Coyote Buttes area of the Paria Canyon-Vermillion Cliffs Wilderness on the Utah/Arizona border.\n",
      "- Hike E2: Coyote Buttes/The Wave\n",
      "An article by Christopher Earls Brennen\n",
      "- A Topo Map of The Wave Hike\n",
      "You can zoom in for a larger version of this map.\n",
      "- Paria Canyon - Coyote Buttes - The Wave\n",
      "- Weather Forecast for North Coyote Buttes and The Wave\n",
      "This link will take you to the NOAA website, where you'll find the forecast for a location 27 miles east of Kanab, UT, which is roughly the location of The Wave. This is the location the BLM site for The Wave points you to for the forecast.\n",
      "Another Wave Rock Formation\n",
      "Check out the amazing Wave in Australia.\n",
      "Recommended Utah Hiking Guides\n",
      "The Wave is actually located in Coconino County, Arizona, but is right near the Arizona/Utah border. And there's lots to see on foot in Utah. Here are two great guide books to help you decide where to go next and how to get there.\n",
      "Explore Utah Canyon Country\n",
      "Recommended by the Glen Canyon Natural History Association, and by me, this book guides hikers to the most compelling destinations in southern Utah's spectacular canyon country.\n",
      "Another Awesome Site to See in Coyote Buttes\n",
      "Let me show you around White Pocket. (pictured below)\n",
      "Sueanne and I had a day to spend exploring before we could use our permit for The Wave, so we spontaneously decided to visit this incredible place she'd heard about from a friend. If there's anything that can possibly top The Wave, White Pocket might be it. And no permit necessary ... as long as you can get there.\n",
      "This content is accurate and true to the best of the author’s knowledge and is not meant to substitute for formal and individualized advice from a qualified professional.\n",
      "Questions & Answers\n",
      "Question: Are dogs allowed to hike with you in Coyote Butte? Also, can you hike during the month of December?\n",
      "Answer: Yes and yes. Re: dogs, the BLM site says, \"Dogs are allowed. They must be kept under control at all times and you must pack out their waste.\" It probably goes without saying, though, that during the summer -- and even in late spring and early fall -- it gets VERY hot out there, and the sand gets extremely hot, so I would never bring a dog during those months. As far as hiking in December, yes. It would certainly be a lot cooler/more comfortable for both humans and dogs. Here's the BLM site for more information: https://www.blm.gov/programs/recreation/permits-an...\n",
      "© 2009 Deb Kingsbury\n",
      "What Do You Think of the Wave? Have You Been There?\n",
      "Deb Kingsbury (author) from Flagstaff, Arizona on July 08, 2020:\n",
      "Thanks, John! It's an amazing place. I'm glad you finally were able to get a permit ... and that you were there to help those ladies out. It may not be a long hike, but, yes, it is possible to get off-track, and with the heat out there, people definitely get in trouble. Thanks for commenting.\n",
      "John Neff on July 07, 2020:\n",
      "Incredibly beautiful hard to get lucky One of my best friends lives in apple valley backs up to gooseberry Mesa our 1st attempt was a failure went out to visit 2 years later and we got lucky got our name drawn for last 2 spots ranger station is middle of nowhere get a brochure with 13 landmarks fairly easy hike but could see how people get lost met to older women who followed some people in im older also 60s we started in the late morning I have a bunch of amazing photos most people had left and the 2 gals asked if we could help them get back one was in good shape the other not We helped them i held the ladies hand on some more difficult spots shared some beer with them when we got back said we were their garden angles who rescued them they were old friends that would do a trp together once a year they got a spot from the internet\n",
      "Deb Kingsbury (author) from Flagstaff, Arizona on December 02, 2019:\n",
      "That's great you got a permit and were able to go. It's definitely worth going back to see the second wave AND places beyond. There's a really awesome canyon not far from the wave and second wave.\n",
      "Gail, Dan & Ruth on December 01, 2019:\n",
      "Just hiked the wave this past October. Absolutely amazing. Can't even put into words how beautiful and incredible this experience was. Got permit in person at the Kanab Ranger station on our second try. Didn't know about the \"2nd wave\". Will just have to go back!\n",
      "CARMEN-2007 on May 01, 2018:\n",
      "I felt like if I was in another world, in a dream, more than in a dream...it was absolutly amazing. Very blue sky in contrast with all the colors and textures. After discovered the wave...I walked up for a while to the other wave and a bit more, and watching all that cannyon and desert...I crayed.\n",
      "Amy Yvonne Thompson on August 16, 2014:\n",
      "I live in Snow Canyon, and you want to make sure to take plenty of water, sunscreen, hat, and companion. You did something I keep thinking of doing, and it really is a spectacular sight, even prettier in person. If you are traveling to the area, check out some of the tourist guide attractions in the surrounding areas. Resorts, tour guides, food, entertainment, etc.\n",
      "RainFern on July 29, 2014:\n",
      "I haven't been to see The Wave, \"yet\". But I'd love to see it! It's not too far from me. Thanks for making such an informative Lens! I'll definitely have to revisit here a few times to absorb all of the information. Well done! This Lens is brilliant! Your pictures are absolutely wonderful!\n",
      "tkdrules29 on July 20, 2014:\n",
      "fibonacci1123 on July 17, 2014:\n",
      "AWESOME lens. Beautiful. Bravo.\n",
      "LoriBeninger on July 11, 2014:\n",
      "Robert Connor from Michigan on June 17, 2014:\n",
      "Awesome rock formations!\n",
      "Linda Hoxie from Idaho on June 08, 2014:\n",
      "Once again you have shared such beauty with us, love this lens and all your knowledge that goes into writing it. I would have had no idea that you had to have a permit to see it. This is just one of the few things we have yet to see in Utah/Arizona area. Thank you!\n",
      "Giovanna from UK on June 05, 2014:\n",
      "Beautiful place - i love to go there one day. I love you photos too.\n",
      "Merry Citarella from Oregon's Southern Coast on April 14, 2014:\n",
      "Amazing! I'd love to see it in person, but your photos are wonderful.\n",
      "Stephen J Parkin from Pine Grove, Nova Scotia, Canada on April 14, 2014:\n",
      "No but it would be something to remember if I ever got there!\n",
      "Robert Connor from Michigan on April 07, 2014:\n",
      "Real nice but we would be worried about snakes & spiders. haha\n",
      "lidialbuquerque on April 02, 2014:\n",
      "Amazingly beautiful! I've never been there, but definitely want to visit soon!\n",
      "Leah J. Hileman from East Berlin, PA, USA on April 01, 2014:\n",
      "Came back to give a BOOST and to say that your lens will be featured on the USA Coast-To-Coast Travel blog on wordpress soon! Great lens. Beautiful pictures and loads of useful information for potential travelers.\n",
      "blestman lm on March 16, 2014:\n",
      "Awesome formation. I went to Arizona last October and ended up at the Grand Canyon. Would have liked to have taken in \"the wave\" too. It looks mystical. Thanks for the lens\n",
      "TerriCarr on March 12, 2014:\n",
      "I have been to Red Rock country but not to this particular place. It must be pretty awesome!\n",
      "Julie Parks from Chula Vista, CA on March 02, 2014:\n",
      "Awesome pictures. It amazing how nature creates such beauty, like The Grand Canyon. Thanks for making this lens. The lines and colors make them absolutely beautiful..\n",
      "sethandressen on February 13, 2014:\n",
      "Awesome photography. These places are simply amazing. The contours and the lines are simply magical.\n",
      "jamer76 on February 01, 2014:\n",
      "Sorry, one more question. My family is very used to hiking/running with Vibram Fivefingers/barefoot/minimalist and we haven't worn \"boots\" in years. I know everything warns you to wear sturdy footwear, but I think we will be fine with our minimalist footwear. Am I being naÃ¯ve? Thanks!\n",
      "jamer76 on February 01, 2014:\n",
      "Hi! We got picked for the hike this year 2014 on May 20th. Any idea if a four-wheel drive is necessary? Some people have suggested a guide to the Buttes because the roads can become impassable. Thanks for any info!\n",
      "Max Globe on January 30, 2014:\n",
      "Wow, those lines are crazy! Such an amazing place, I would have made some stunning pictures thre)\n",
      "Lynn Klobuchar on January 08, 2014:\n",
      "bikinjudy on November 08, 2013:\n",
      "It is everything the pictures show. When hiking during the summer months do not think that water in a camelback is enough. Carry extra bottles of water. After I hiked there in summer of 2013....3 people died because of not having enough water and not being in good shape. The hike into The Wave is relatively easy but after spending 4-5 hours in the heat at The Wave....the return hike out is deceptive and I actually ran out of water. I had on a camelback and a huge bottle of water that was frozen when I began. I am very lucky that I made it out alive!! I thought it was awesome. This is something that was carved by nature. I have seen Machu Pichu and hiked up there along the\n",
      "Salcantay trail and yet, this trip to The Wave was much harder coming out and more memorable. You will love it if you can win the lottery to get in. JudyP-M\n",
      "Andrew4M on August 08, 2013:\n",
      "Awesome, the photos are thrilling.\n",
      "josietook on July 31, 2013:\n",
      "Fantastic, really love the photo under the heading \"What Forces Created The Wave?\"\n",
      "Ean Brandon from United States on July 19, 2013:\n",
      "I live just two hours from the wave and have never been there!\n",
      "DEFINITELY GOING THERE ASAP\n",
      "David Edward Lynch from Port Elizabeth, South Africa on July 05, 2013:\n",
      "Looks like an amazing place!\n",
      "Ash2013 on June 12, 2013:\n",
      "Wow! Totally awe inspiring, thanks for showing us these beautiful pictures.\n",
      "anonymous on May 13, 2013:\n",
      "ConvenientCalendar on May 07, 2013:\n",
      "The pictures are amazing!\n",
      "mariacarbonara on May 04, 2013:\n",
      "Truly stunning. Like one of those must do trips!\n",
      "ian-patrick-716 on April 26, 2013:\n",
      "Margot_C on April 25, 2013:\n",
      "That's awesome! Would love to go someday. Thanks for sharing.\n",
      "webscribbler on April 11, 2013:\n",
      "Thank you so much for sharing your adventure. Based on the lottery system it seems that very few people get an up close view like yours. The hike puts it out of reach for me. Your wonderful lens is a great way for people like me to see such out of the way wonders that would otherwise be inaccessible to us.\n",
      "RickyDawn1 on April 11, 2013:\n",
      "agagata lm on April 10, 2013:\n",
      "WOW! The place is stunning! Thank you very much for sharing it with us!\n",
      "danniblaze on April 09, 2013:\n",
      "Great lens, it looks absolutely beautiful there.\n",
      "bethann21 on April 05, 2013:\n",
      "Been there and other red rock areas. It is truly amazing. Nice lens. Great information. Everyone should see it at least once in their lives!\n",
      "chocochipchip on March 30, 2013:\n",
      "What an adventure!\n",
      "anonymous on March 30, 2013:\n",
      "Never been but your beautiful lens had made me seriously want to.\n",
      "ajayonline on March 29, 2013:\n",
      "one of the best places to be in.\n",
      "Rowan Chisholm from Washington state on March 27, 2013:\n",
      "I'd love to see this in person. I had seen pictures of this before, but had had no idea where it was or what sort of terrain it was in. This lens really shows what it's like to go there. Thanks for sharing the hike as well as the destination.\n",
      "Loretta Livingstone from Chilterns, UK. on March 26, 2013:\n",
      "Wow! What glorious colours. God is the top artist! Nature is amazingly beautiful. Thanks for sharing. Awesome photos.\n",
      "Loretta Livingstone from Chilterns, UK. on March 26, 2013:\n",
      "Wow! What glorious colours. God is the top artist! Nature is amazingly beautiful. Thanks for sharing. Awesome photos.\n",
      "Laurabpeterson on March 25, 2013:\n",
      "Stunning! I love your photos. What a fantastic guide to getting to the Wave! I love you lens and I will be adding it to my lens here: http://squidoo.com/mountain-pictures-i-love.\n",
      "alina nicoleta92 on March 25, 2013:\n",
      "It seems like a really great place and the pictures are marvelous:)\n",
      "BabysownRoom LM on March 23, 2013:\n",
      "After viewing all your pictures I want to hike it again! :) Thanks for sharing and reminding me what a wonderful world we live in.\n",
      "seosmm on March 23, 2013:\n",
      "What an amazing place. Would be a great place for beautiful photos.\n",
      "Michelllle on March 22, 2013:\n",
      "Wow. Beautiful lens. I wanna go.\n",
      "Meyani on March 22, 2013:\n",
      "mischiefmydear on March 22, 2013:\n",
      "It's absolutely beautiful! Looks well worth the work required to get a permit... and definitely will be going on my \"to visit\" list!\n",
      "davidtrust on March 21, 2013:\n",
      "That looks cool! Gotta add that to my ever expanding list of places to see!\n",
      "ArleneKroeker on March 20, 2013:\n",
      "Captivating photos. Thanks for showing this part of the country.\n",
      "reells on March 18, 2013:\n",
      "Beautiful pics! I would love to see it.\n",
      "anonymous on March 17, 2013:\n",
      "What an awe-inspiring lens. As an avid \"ex traveller\" but now an armchair traveller I think you've managed to get the travel bug stirring again. I am a newbie here so am absolutely loving looking around and discovering all about Squidoo.\n",
      "VladJohn888 on March 16, 2013:\n",
      "Amazing. good job!\n",
      "MusicMadness LM on March 15, 2013:\n",
      "Pretty spectacular stuff mate. I'll have to add this place to my bucket list destinations.\n",
      "Vera-S on March 15, 2013:\n",
      "Beautiful breathtaking pictures. Great lens.\n",
      "petertraoassi2 on March 14, 2013:\n",
      "Surreal! It looks like Tatooine.\n",
      "Ana Dilber on March 12, 2013:\n",
      "Great lens, I really love the topic. Hiking is one of my favorite hobbies, hope I will have opportunity to try this.\n",
      "pericaluic on March 11, 2013:\n",
      "Ben Reed from Redcar on March 10, 2013:\n",
      "An interesting lense - thank you for sharing.\n",
      "anonymous on March 10, 2013:\n",
      "Your lens is so informative â¦ keep up the good work!!!!\n",
      "anonymous on March 09, 2013:\n",
      "You may have just added this to my bucket list. Thanks for sharing this\n",
      "hovirag on March 09, 2013:\n",
      "It is indeed breath taking! I really hope I can visit it one day!\n",
      "tobydavis on March 09, 2013:\n",
      "Fantastic photographs! Such an amazing piece of nature - breathtaking!\n",
      "myoyster1957 on March 08, 2013:\n",
      "Must have been a great hike, nice lens with really good photos.\n",
      "DvdMovieGirl on March 08, 2013:\n",
      "I had never heard of the Wave. But one day be sure I will come and hike that trail and try to take photographs as brilliant as yours! I learn so much on Squidoo!\n",
      "JeffGilbert on March 08, 2013:\n",
      "There's so much great geology in Utah. Like Bryce Canyon, this is one of the wonders of the world.. :)\n",
      "jackprost on March 08, 2013:\n",
      "great lens, i like hiking\n",
      "Laurel Johnson from Washington KS on March 06, 2013:\n",
      "Breathtaking photos. Loved this lens!!\n",
      "poldepc lm on March 06, 2013:\n",
      "great information; thanks for sharing...\n",
      "goldenrulecomics from New Jersey on March 05, 2013:\n",
      "top-notch-shop on March 05, 2013:\n",
      "Looks a great place to visit\n",
      "webmavern on March 05, 2013:\n",
      "Wow it's amazing! What a beautiful place to visit.\n",
      "Fcuk Hub on March 05, 2013:\n",
      "I don't know what to say. Just beautiful :)\n",
      "MarionElodie on March 05, 2013:\n",
      "I think it's amazing! Hopefully I'll be able to make it there one day.\n",
      "traveldestinations on March 04, 2013:\n",
      "Blessed! Congratulations on your lens. The photos alone are amazing.\n",
      "SquidooMBA on March 04, 2013:\n",
      "Looks beautiful. Thanks for sharing.\n",
      "LeslieMirror on March 04, 2013:\n",
      "I can't but stop adoring what amazing gifts our nature can provide us with. Such beautiful places make us feel being in a fairy-tail!\n",
      "rattie lm on March 04, 2013:\n",
      "In the true sense of the word, that is absolutely awesome. I can't wait to do this! Congratulations on a well-earned purple star.\n",
      "Allison Whitehead on March 03, 2013:\n",
      "Amazing lens and well worth blessing :)\n",
      "PiccadillyPunkin on March 03, 2013:\n",
      "Absolutely AMAZING! I loved your lens...the beautiful images, the great info about The Wave...it's now on my bucket list. Awesome!\n",
      "MichaelDubrovnik on March 02, 2013:\n",
      "It looks amazing!\n",
      "nicksanders lm on March 02, 2013:\n",
      "I love these photos - they're really different. I suppose it's quite surreal walking around on the wave. Looks like it might be worth trying when I'm over in that part of the US though; I'm kinda drawn to strange things.\n",
      "Christine and Peter Broster from Tywyn Wales UK on March 01, 2013:\n",
      "I would love to see these. Lovely photos\n",
      "willoconner on February 28, 2013:\n",
      "DebW07 on February 27, 2013:\n",
      "Faye Rutledge from Concord VA on February 24, 2013:\n",
      "Beautiful photos! :)\n",
      "Sherry B19 on February 23, 2013:\n",
      "Beautiful pictures! It looks like it is an amazing place to visit. I really enjoyed reading your lens and found it very informative...I never knew about this place before reading your lens. Thank you for sharing this!\n",
      "anonymous on February 23, 2013:\n",
      "Oh my god, such beautiful pictures! I am sure that this was an amazing experience for you! One I wish I could go on one day!\n",
      "Ayngel Overson from Crestone, Co on February 22, 2013:\n",
      "Always a pleasure to read your work, but the images on this one were truly stunning! Well done, and well worth a front page spot.\n",
      "crbphotography on February 22, 2013:\n",
      "Unbelievable photographs. I have got to go to the Wave and Coyote Buttes. On my bucket list.\n",
      "air ambulance s on February 22, 2013:\n",
      "Your pictures look amazing! I enjoyed your lens so much. Thanks for sharing this.\n",
      "worldwidesouven on February 19, 2013:\n",
      "I like this area so much! You were lucky to get this permit. Thank you for detalied explanation and links about how to get it!\n",
      "beaworkathomemom on February 16, 2013:\n",
      "WOW! Such a beautiful place. The pictures are stunning, but I'm sure in person it's even more spectacular.\n"
     ]
    }
   ],
   "source": [
    "fineweb_edu = load_dataset(\"HuggingFaceFW/fineweb-edu\", \"sample-10BT\",  split='train', cache_dir=CACHE_DIR)\n",
    "\n",
    "print(\"FineWeb-Edu is ready.\")\n",
    "print(\"dataset size in gb:\", fineweb_edu.dataset_size / (1024**3))\n",
    "print(\"Number of entries:\", len(fineweb_edu))\n",
    "print(\"-\"*50)\n",
    "print(\"Example entry:\")\n",
    "print(fineweb_edu[random.randint(0, len(fineweb_edu)-1)]['text']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenWebText2 dataset loaded.\n",
      "Dataset size in GB: 37.03822539001703\n",
      "Number of entries: 8013769\n",
      "--------------------------------------------------\n",
      "Example entry:\n",
      "Mission Not Accomplished\n",
      "\n",
      "The war in Libya is a good war — or at least, it should and could be. But it is certainly not a smart war and may well turn into a debacle. Bringing down Col. Muammar al-Qaddafi’s tyranny would be a major strategic and humanitarian victory in the Middle East. That achievement would be even more stunning if a democratic government, brought to power by Libyans themselves, replaced Qaddafi. Although the Libyan rebels will undoubtedly need Western help — and are rightly receiving it — the credit will be theirs: The American Revolutionaries needed French arms to defeat the British, but French help did not tarnish their victory.\n",
      "\n",
      "Yet the chances of such favorable outcomes have been diminished by America’s own president. Barack Obama, despite his forceful speech on Monday, March 28, is proving to be singularly ungifted in executive talent, let alone in the qualities that are needed in the leader of the Western alliance. Obama’s Libya policy has been marked by an erratic, improvisational, and amateurish character. Already the administration is quietly warning that the war may drag on through the rest of the year, if not beyond it. While Obama might claim success early on, given the vague mission of protecting civilians, we should not be fooled into thinking that an ongoing civil war represents a victory for American arms. Indeed, a prolonged stalemate would be a disaster. Wounded, vengeful, but undefeated, Qaddafi would pose a greater danger than ever. He could resume his practice of terrorist attacks on Western targets, working perhaps through jihadi elements such as the Libyan Islamic Fighting Group, hundreds of whose members he has released from prison.\n",
      "\n",
      "A protracted civil war in Libya could have effects beyond its borders. It could lead competing outside powers — France, Turkey, or even China — to back different Libyan factions. U.S. forces and resources would be tied down even as the United States seeks to wind down in Iraq and defeat a resurgent Taliban in Afghanistan. On the other hand, a premature exit would undermine American credibility in a region that already doubts Obama’s steadfastness. Just as the administration’s mishandling of last year’s oil spill in the Gulf of Mexico revealed its ineptitude in domestic matters, its mismanagement of the Libya intervention may become emblematic of its haplessness in foreign affairs.\n",
      "\n",
      "The Obama administration’s most glaring mistake in its approach to Libya is the central weight it has given to the United Nations. Hanging America’s hat on U.N. approval has caused a mismatch between Obama’s stated policy goal — that Qaddafi must \"go\" — and the limited means provided by U.N. approval for economic sanctions and civilian protections. Even at this early stage of the conflict, Obama’s policy has created a large gap between U.S. strategic ends and U.N.-authorized means.\n",
      "\n",
      "First, Obama has announced that in no circumstances will the United States introduce ground troops into Libya. Even if the United States was not planning to take that step, it was an unpardonable mistake for the president to have said so publicly. As simple international bargaining theory demonstrates, the threat of escalating a conflict by a party with superior resources should lead to a more favorable settlement. The threat of invasion might have convinced Qaddafi to leave power or his generals to take matters into their own hands. Obama’s announcement to the contrary can only have strengthened Qaddafi’s resolve to hang on. Taking the option of ground troops off the table at the very outset of hostilities helpfully informed an enemy of U.S. limits and undercut the coalition’s position.\n",
      "\n",
      "Furthermore, if America’s strategic goal is — as Obama proclaims — the overthrowing of the Libyan regime, it may well need to introduce ground forces to do that, especially if NATO’s use of air power remains highly circumscribed. (NATO Secretary-General Anders Fogh Rasmussen has said that the alliance \"will implement all aspects of the U.N. resolution. Nothing more, nothing less.\") Air power is useful to a point: It can disrupt Qaddafi’s logistics and prevent the movement of his forces across the vast desert spaces between Libya’s cities. But it cannot take and hold ground. Air power is far more likely to succeed if combined with significant military operations on land — as it was in the two Iraq wars. NATO’s air power did not bring down Slobodan Milosevic in the Kosovo war. It may have forced his withdrawal from Kosovo, but even there it was supported by the land forces of the Kosovo Liberation Army. Without the use of significant land forces — whether provided by better armed and trained rebels, more defectors from Qaddafi’s side, NATO, or the United States — stalemate rather than regime change seems the likely result. As Director of National Intelligence James Clapper warned, the meager forces fielded by the rebel government alone cannot overcome the superior firepower of the Qaddafi military.\n",
      "\n",
      "Yet Obama and his senior advisors have endlessly repeated that the United States will play only a marginal role in NATO’s future military efforts in Libya: The country’s main missions going forward will apparently be limited to reconnaissance, search and rescue, and communications jamming. In its desperation to hand off responsibility, the United States has again undercut Western efforts and fed Qaddafi’s hopes of survival. Without substantial U.S. involvement, will the British, French, and other NATO air forces arrayed against Qaddafi be sufficient to bring him down?\n",
      "\n",
      "To be sure, even without significant U.S. \"kinetic\" support, NATO is — on paper — more than equal to the task. Qaddafi’s army had a mere 50,000 poorly trained and equipped troops at the start of the rebellion (half of them draftees), and many of those troops defected to the insurgents. Qaddafi deliberately kept his military small and weak, seeking to avoid a coup d’état like the one that brought him to power in 1969. True, Qaddafi has bolstered his forces by hiring mercenaries (allegedly paying them from the large gold reserves held in Libya’s Central Bank). He can also count on special forces such as the estimated 10,000 Russian-trained troops commanded by his son Khamis (who is rumored to have been killed). In size, equipment, and quality, his military assets do not hold a candle to those of the Western armies now massed in the region, but without U.S. military leadership it seems unlikely that NATO countries have the ability or the stomach to fight it out on the ground. This, after all, is the lesson of the wars of the 1990s in the Balkans, where European countries could not stop a gruesome civil war on their borders without American intervention.\n",
      "\n",
      "The administration’s attachment to the sanitized air power version of warfare has it ignoring immediate, practical steps it could take to strike at Qaddafi. According to the Treasury Department, the U.S. government has frozen at least $33 billion in Libyan assets — the largest freeze ever under any U.S. sanctions order. The administration should use these funds to bribe Qaddafi’s generals or mercenaries to overthrow him or to at least supply the rebels with heavy weapons. (The United States’ support today need not make the same mistake it did in Afghanistan in the 1980s, when it arguably provided weapons to groups that would later morph into the Taliban, other Afghan warlords, and al Qaeda. The United States does not need to supply the Libyan rebels — who are fighting a small, relatively unsophisticated loyalist army — with the same amount and quality of weapons as it did to Afghan rebels opposing the top-flight Soviet military.) Regardless, Qaddafi’s now-frozen assets are Libyan, not American. And if the Obama administration were to recognize the rebel movement, or elements of it, as the government of Libya, that body might permit the use of unblocked assets for such war-related purposes. Moreover, recognizing the rebels — as France and Qatar have already done — would demonstrate the strength of America’s commitment to bring Qaddafi down.\n",
      "\n",
      "Worst of all, perhaps, has been Obama’s determination to ensure the United Nations has played a leading role in the Libya intervention. As a result of an embarrassing, last-minute policy switch on the administration’s part, the Security Council adopted Resolution 1973 — which authorizes the use of \"all necessary measures\" to protect Libyan \"civilians and civilian populated areas under threat of attack.\" Although lauded as a diplomatic victory for the administration, the resolution’s main effect is to straitjacket U.S. military and policy choices. By its own terms, the resolution does not authorize the coalition to bring Qaddafi down. Yet that is precisely the proclaimed policy objective of the United States, Britain, and France. For the sake of obtaining the Security Council’s approval, the Obama administration has denied itself and its coalition partners the full use of the military instrument to achieve its core policy goal.\n",
      "\n",
      "The resolution does not in terms authorize NATO or the coalition to train the rebel forces or supply them with weaponry. Some coalition members have therefore questioned whether they may lawfully provide aid. NATO has not authorized its forces to join with the rebels if they advance on cities in western Libya that are still in Qaddafi’s grip. The resolution even seems to require NATO to resist any rebel attacks on Qaddafi’s forces if those attacks are likely to bring about collateral civilian casualties. Incredible as it may sound, CNN reports that a \"senior U.S. administration official … did not rule out the possibility of an attack on the rebels if they were to go on the offensive and strike cities with civilian populations, now held by pro-Gadhafi forces.\" So if rebel forces are poised to attack Qaddafi’s stronghold in Tripoli, the resolution may require NATO to take sides against the rebels, if (as is inevitable) their attack endangers the city’s civilian population!\n",
      "\n",
      "The resolution also displays other, less visible flaws. For instance, it does not authorize an attempt to seize Libyan oil fields still under Qaddafi’s control. But even though government forces have recently been pushed out of the oil-rich eastern part of Libya, there remains a serious risk that Qaddafi might, in desperation, destroy them in order to punish his Western enemies. He has already threatened to turn the entire Mediterranean Sea into a theater of war, and he has the example of Saddam Hussein’s destruction of Kuwait’s oil fields in 1991 as precedent. Yet the United Nations has given no permission to guard against this obvious threat.\n",
      "\n",
      "The resolution also does not authorize NATO to take out Qaddafi’s stockpile of chemical weapons (unless, perhaps, he signals the intent to use them against his own people). Even assuming that Qaddafi lacks the means to deliver these weapons, their destruction ought to be a primary objective for NATO, not only for the sake of the Libyan people, but for the safety of coalition forces in the area. If a democratic government succeeds Qaddafi, it would not certainly need chemical weapons; if Islamic radicals succeed him, we should ensure that these weapons do not fall into their hands.\n",
      "\n",
      "Considering Resolution 1973’s handcuffs, it is likely that NATO will eventually either ignore it or construe it disingenuously. U.N. approval has virtually no offsetting benefits, except for a thin veneer of international legality for a no-fly zone, an embargo, and limited efforts to protect Libyan civilians. It only provides countries like Russia and China the opportunity to attack American intervention by claiming it runs beyond the writ of some amorphous \"international community\" whose will is expressed in a U.N. resolution — a resolution that pretends that the goals, strategies, and tactics of war can be reduced to a clear legal document. But this imposes a straitjacket on a coalition military faced with unforeseen and constantly changing circumstances and conjures written political agreement where in fact there is none.\n",
      "\n",
      "Obama accepted these political and military handicaps, worrying far more about winning the approval of the United Nations than of the U.S. Congress. Although it is clear that the president has the constitutional authority to act on his own in this instance, it makes good political sense to get Congress’s support. But the current administration, like Bill Clinton’s and Jimmy Carter’s administrations before it, seems swayed by the view, born of the Vietnam War, that American power in the world is the problem, not the solution. Rather than use military force in pursuit of clear American interests, Obama and his aides want to submerge U.S. action into a dense network of international institutions and multilateral coalitions. Only by taking a second seat to France, Britain, or the Arab League can the United States assure the world, and its own people, that it is acting out of altruistic rather than purely American national interests and doesn’t covet a third Middle East war.\n",
      "\n",
      "Thanks to Resolution 1973’s restraints on the Libyan intervention, the administration will soon discover that placing its hopes on the United Nations was a mistake. It is an institution as formal as it is powerless — bound up by a huge, wasteful bureaucracy and antiquated legal rules that only prevent the great powers of today from using force to actually stop human rights crises, as with the civil war in the Ivory Coast. The United Nations’ fundamental principle is to declare the \"territorial integrity\" and \"political independence\" of each country and to prohibit intervention in the internal affairs of member states. In its eyes, North Korea, the most brutal totalitarian government in the world, is the equal of the United States, which has done more than any country in the postwar period to protect freedom and democracy.\n",
      "\n",
      "The U.N. charter contains even deeper flaws. Its provision for the use of force is identical to law enforcement: that force can only be used against an attacker; otherwise, the state has a monopoly on violence. The charter shares the same goal as domestic law — to drive violence down to zero. But this is a mistake on two grounds. First, there is no world government that can effectively police countries from using force against each other. Second, the optimal use of force in international politics should not be zero; instead, it should be permitted where its use would increase global welfare.\n",
      "\n",
      "The charter and its obsolete procedures ignore that today’s world faces problems that are worse than war. Failed states, massive human rights disasters, rogue nations pursuing weapons of mass destruction, and international terrorist groups all threaten greater harm than those of military intervention. These are not hypotheticals; we need only reflect on the costs of recent U.N. inaction: Saddam Hussein killed hundreds of thousands of his own citizens, some with weapons of mass destruction. Rwanda was rent by genocide. Serbia killed thousands in its campaign of ethnic cleansing. And hundreds of thousands have died in conflicts in Sudan and central Africa.\n",
      "\n",
      "Certainly, the United States does not have an obligation to intervene everywhere to stop all wars, fix all failed states, remove all dictators, and pursue all terrorists groups. But the international political and legal system creates perverse incentives for the United States and its allies to avoid those cases where they can do good. Proponents of the United Nations may argue that Resolution 1973 shows that the global body has progressed — that it has learned from history and will not shy from authorizing the use of force in situations where humanitarian issues compel action. They are wrong. The milquetoast authorization of limited combat highlights that the opposite is true.\n",
      "\n",
      "Without a clear remit for a satisfactory endgame in Libya, the likelihood that we will find ourselves with a divided, chaotic state in that country is high; the likelihood that future necessary action to prevent such eventualities will be handcuffed is almost a certainty. It is high time to replace the U.N. Charter with international rules that encourage countries to end human rights abuses, fix failed states, and oppose rogue nations and terrorist groups.\n",
      "\n",
      "Instead, the United States and its allies should form a Concert of Democracies. No international bureaucracy or complicated rules on the use of force are needed. Instead, the great democracies should collectively decide, case by case, whether to intervene. A concert would allow these countries to share the costs of intervention. And it should exclude countries like Russia and China; they should have no voice until they show a corresponding desire to shoulder global responsibilities.\n",
      "\n",
      "The one positive in all this? If Libya at least brings about a rude awakening for the Obama administration on the follies of multilateralism and leads to the emergence of a new international security system, it will have done far more good than simply dragging the United States into a civil war.\n"
     ]
    }
   ],
   "source": [
    "# OpenWebText2 dataset\n",
    "owt2 = load_dataset(\"Skylion007/openwebtext\", split=\"train\", cache_dir=CACHE_DIR)\n",
    "print(\"OpenWebText2 dataset loaded.\")\n",
    "print(\"Dataset size in GB:\", owt2.dataset_size / (1024**3))\n",
    "print(\"Number of entries:\", len(owt2))\n",
    "print(\"-\"*50)\n",
    "print(\"Example entry:\")\n",
    "print(owt2[random.randint(0, len(owt2)-1)]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Q&A data to improve the model's ability to answer questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q&A dataset loaded.\n",
      "dataset size in mb: 46.480509757995605\n",
      "Number of entries: 120959\n",
      "--------------------------------------------------\n",
      "Example entry:\n",
      "Why is proper curing important in automotive painting? \n",
      " Proper curing is crucial for allowing paint to fully bond with the underlying surface, preventing premature cracking, peeling, or issues that impact the final product's longevity and overall quality.\n"
     ]
    }
   ],
   "source": [
    "q_a1 = load_dataset(\"agentlans/text-sft-questions-answers-only\", split='train', cache_dir=CACHE_DIR)\n",
    "print(\"Q&A dataset loaded.\")\n",
    "print(\"dataset size in mb:\", q_a1.dataset_size / (1024**2))\n",
    "print(\"Number of entries:\", len(q_a1))\n",
    "print(\"-\"*50)\n",
    "print(\"Example entry:\")\n",
    "index = random.randint(0, len(q_a1)-1)\n",
    "print(q_a1[index]['question'][:500], \"\\n\", q_a1[index]['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Instruct dataset loaded.\n",
      "dataset size in gb: 0.09901080373674631\n",
      "Number of entries: 84784\n",
      "--------------------------------------------------\n",
      "Example entry:\n",
      "ELI5: Howcome when I drink salty sea-water I vomit but drinking water while eating heavily salted popcorn is fine? \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " '\\n',\n",
       " \"There is much much much more salt in salt water.  When you eat popcorn then drink water you are essentially diluting the salt content.  When drinking salt water you aren't diluting anything,  but you are increasing your body's salt content. (edit to fix auto correct - lol) \")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#euclaise/reddit-instruct\n",
    "reddit_instruct = load_dataset(\"euclaise/reddit-instruct\", split='train', cache_dir=CACHE_DIR)\n",
    "# reddit_instruct = load_dataset(\"Felladrin/ChatML-reddit-instruct-curated\", split='train', cache_dir=CACHE_DIR)\n",
    "print(\"Reddit Instruct dataset loaded.\")\n",
    "print(\"dataset size in gb:\", reddit_instruct.dataset_size / (1024**3))\n",
    "print(\"Number of entries:\", len(reddit_instruct))\n",
    "print(\"-\"*50)\n",
    "print(\"Example entry:\")\n",
    "index = random.randint(0, len(reddit_instruct)-1)\n",
    "print(reddit_instruct[index]['post_title'][:500], reddit_instruct[index]['post_text'][:500]), \"\\n\", reddit_instruct[index]['comment_text'][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpaca dataset loaded.\n",
      "dataset size in mb: 44.06797695159912\n",
      "Number of entries: 52002\n",
      "--------------------------------------------------\n",
      "Example entry:\n",
      "What is the impact of deforestation on wildlife? \n",
      " Deforestation has a range of consequences for wildlife, including habitat loss, disruption of ecosystems and food webs, displacement of species, increased competition, and increased vulnerability to predation. Additionally, deforestation can increase the risk of climate change, resulting in altered temperatures and unpredictable weather patterns that further disrupt wildlife habitats.\n"
     ]
    }
   ],
   "source": [
    "# tatsu-lab/alpaca ( for Q&A fine-tuning )\n",
    "alpaca = load_dataset(\"tatsu-lab/alpaca\", split='train')\n",
    "print(\"Alpaca dataset loaded.\")\n",
    "print(\"dataset size in mb:\", alpaca.dataset_size / (1024**2))\n",
    "print(\"Number of entries:\", len(alpaca))\n",
    "print(\"-\"*50)\n",
    "print(\"Example entry:\")\n",
    "index = random.randint(0, len(alpaca)-1)\n",
    "print(alpaca[index]['instruction'][:500], \"\\n\", alpaca[index]['output'][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizer setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project i use tiktoken for the tokenizer, as it is the same tokenizer used by OpenAI for their models.\n",
    "\n",
    "I use the \"gpt2\" encoding which is a byte pair encoding (BPE) tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_base = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "tokenizer = tiktoken.Encoding(\n",
    "    name=\"rob-tokenizer\",\n",
    "    pat_str=tokenizer_base._pat_str,\n",
    "    mergeable_ranks=tokenizer_base._mergeable_ranks,\n",
    "    special_tokens={\n",
    "        **tokenizer_base._special_tokens,\n",
    "        \"<|im_start|>\": 50257,\n",
    "        \"<|im_end|>\": 50258,\n",
    "        \"<|pad|>\": 50259,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test of the byte pair encoding tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2061, 318, 24207, 1616, 2587, 30, 314, 2342, 257, 7684, 286, 1097, 5861, 290, 484, 1561, 546, 275, 32512, 7021, 290, 884, 11, 1312, 373, 11263, 644, 275, 32512, 318, 290, 1312, 18548, 1064, 597, 2562, 7468, 284, 644, 340, 318, 24207, 1616, 318, 655, 262, 1438, 329, 257, 16058, 286, 6147, 13, 554, 262, 29393, 995, 340, 338, 1690, 973, 355, 257, 1790, 1021, 329, 3354, 326, 547, 3235, 1389, 503, 286, 257, 1263, 2512, 286, 2587, 11, 355, 6886, 284, 11721, 3350, 654, 810, 44030, 6147, 318, 19036, 656, 257, 15936, 12070, 503, 286, 9629, 6147, 13, 7080, 3191, 318, 517, 5789, 329, 1588, 17794, 475, 340, 460, 779, 1365, 3081, 286, 21782, 290, 318, 4577, 284, 787, 329, 4833, 17794, 588, 3234, 3354, 13]\n",
      "Decoded text:\n",
      "What is Billet material? I watch a bunch of car videos and they talk about billet blocks and such, i was wondering what billet is and i cant find any easy explanation to what it is Billet is just the name for a chunk of metal. In the automotive world it's often used as a short hand for parts that were machined out of a big block of material, as opposed to cheaper castings where molten metal is poured into a mold pressed out of sheet metal. Machining is more expensive for large quantities but it can use better quality of metals and is easier to make for smaller quantities like race parts.\n",
      "Sample text length in characters: 594\n",
      "Sample text length in tokens: 127\n"
     ]
    }
   ],
   "source": [
    "# test of tokenizer on reddit_instruct\n",
    "sample_text = reddit_instruct[0]['post_title'] + \" \" + reddit_instruct[0]['post_text'] + \" \" + reddit_instruct[0]['comment_text']\n",
    "tokens = tokenizer.encode(sample_text)\n",
    "print(tokens)\n",
    "print(\"Decoded text:\")\n",
    "print(tokenizer.decode(tokens)) \n",
    "print(f\"Sample text length in characters: {len(sample_text)}\")\n",
    "print(f\"Sample text length in tokens: {len(tokens)}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting datasets functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 26209380\n",
      "Finetune dataset size: 257745\n",
      "Example entry from train dataset:\n",
      "{'id': '<urn:uuid:6f09d22c-9e4c-4db2-9334-4e0dad2ab9d9>', 'url': 'https://www.rivalnations.org/back-future-tribulation-part2/', 'title': None, 'text': 'Jesus warned his followers of a Great Tribulation that was to come within one generation. It isn’t some event that will happen in our future. The Great Tribulation started in 66 AD and would come to a close in 70 AD. It was a warning for their future, not ours. Jesus gave many signs of its coming so that it could be avoided. We covered these prophetic signs and how they were fulfilled in Part 1 of this article. The signs were leading up to the complete destruction of Jerusalem, the Temple, and the Temple Age.\\nThe War of Abomination\\nIn the year 66 AD, Florus, the last Roman procurator, stole vast quantities of silver from the Temple. The outraged Jewish masses rioted and wiped out the Roman garrison stationed in Jerusalem. This victory had a terrible consequence: many Jews suddenly became convinced that they could defeat Rome, and the Zealots’ ranks grew exponentially. In response, the Romans mobilized 60,000 heavily armed and highly professional troops. Their first target was the Jewish state’s most radicalized area, Galilee in the north. An estimated 100,000 Jews were killed or sold into slavery.\\nSimon ben Giora, a man who claimed to be the messiah, gathered a large following in revolt and marched towards Jerusalem so he could be “King of the Jews”. Many from Galilee fled to the city thinking they would be safe under this violent messiah. It wasn’t long before infighting began over leadership of the city. Jerusalem was in the midst of a brutal civil war by the time the future Roman emperor, Titus, offered the Jews a chance to surrender. Upon their reviled refusal, the three Roman legions dug a trench five miles long with 13 towers around the city in only three days. Thus Luke 19:43 was fulfilled.\\nThe day on which Titus encompassed Jerusalem was the feast of the Passover. He allowed pilgrims to enter, though Jesus warned that “those in the country should not enter the city” (Luke 21:21). Ignoring him, multitudes came up from all the surrounding country and would soon be trapped inside the city walls.\\nIn expectation of a Roman siege, Jerusalem’s Jews had stockpiled a supply of dry food that could have fed the city for many years. But one of the warring Zealot factions burned the entire supply, apparently hoping that destroying this “security blanket” would compel everyone to participate in the revolt.\\nAs no supplies could now enter the walls, the famine rapidly extended itself, and increasing in horror, devoured whole families. The tops of houses and the recesses of the city were covered with the carcasses of women, children, and aged men. The young men appeared like specters and fell down lifeless in the streets. The dead were too numerous to be interred, and many died while burying others. It is recorded that over 600,000 bodies were allowed to be taken outside the walls before the Romans even entered the city.\\nStarving, the Jews began to be compelled to eat their belts, sandals, grass, and even the manure of oxen. It wouldn’t be long before parents would turn to their defenseless children for food (Deuteronomy 28:53). It is recorded that mothers killed, roasted, and ate their own children. Jesus knew this would happen. As he was carrying his cross, he wept for the women and children of Jerusalem, saying their deaths would be far worse than his (Luke 23:28-29).\\nMany tried to escape the city but were all captured and crucified on crosses. 500 Jews were crucified a day. The Romans did this until every single tree surrounding the city had been cut down and there was no wood left. When it was discovered that some of the deserters had swallowed gold, the Romans ripped open two thousand of them in one night. Titus, touched by these calamities, in person asked the Jews once more to surrender. They did not.\\nIn They Came\\nAfter years of starvation, disease, and civil war, in the summer of 70 AD the walls of Jerusalem were breached by the Romans. They first plundered and then set fire to the houses. They filled the streets with drawn swords in their hands, murdering every Jew whom they met, without distinction. The bodies of the dead choked up all the alleys and narrow passes while their blood literally flowed down the channels of the city in streams.\\nFathers tearfully slaughtered their entire families, in order to prevent them from receiving worse treatment from the Romans. The whole land “was all over filled with fire and blood.” The lakes and seas turned red, dead bodies floating everywhere, littering the shores, bloating in the sun, rotting and splitting apart.1\\nThe Temple Ablaze\\nA Roman soldier, urged, as he declared, by a divine impulse, regardless of the command of Titus, climbed on the shoulders of another and threw a flaming brand into the golden window of the Temple, which instantly set the building on fire. Titus, not having planned to destroy the Temple, made his way to the inner section, the Holy of Holies (thus fulfilling “the abomination of desolation”, in Matthew 24:15).\\nStruck with the magnificence of its architecture and the beauty of its decorations, he renewed his efforts to stop the progress of the flames. He commanded his soldiers to exert all their strength and activity to stopping the fire, and he appointed a centurion of the guards to punish them if they ignored his command. But it was all in vain, the delirious rage of the soldiers knew no bounds, they would not stop their slaughter.\\nThe Romans entering the Temple, with their pagan symbols all over their armor and standards, was an abomination. By comparing Matthew 24:15-16 with Luke 21:20, we can understand that the abomination that caused the desolation of Jerusalem was the Roman soldiers that lay siege to the city. Not only was this fulfilling the words of Jesus, Daniel also prophesied about it (Daniel 9:26).\\nMost scholars think Daniel was originally writing about the desecration of the temple in 168 BC by Antiochus Epiphanes. Jesus saw its echoed fulfillment in Rome’s traumatic desecration of the Temple in 70 AD. Interestingly, dispensationalist Christians view this text as still awaiting fulfillment in the future. Despite the fact that the Jewish Temple has already twice been desecrated, they believe the Daniel prophecy requires that it be desecrated again. Since the temple has been in ruins since the Romans destroyed it in 70 AD, it cannot desecrated it unless it is rebuilt once more—not for its own sake nor for Jewish worship, but so that it can be desecrated one last time in fulfillment of this prophecy from Daniel.\\nThis has not been the view for the majority of Christian history.\\nOne false prophet told the people that they should flee to the Temple in order to behold signs of their deliverance. While they waited in anxious expectation of the promised miracle, the Romans increased the fire to the Temple. Many jumped to their deaths while the majority perished in the flames (Matthew 24:24).\\nSince the golden roof had melted down in between the bricks of the Temple, the Romans tore each one apart to retrieve it (Luke 19:44). About 97,000 Jews were enslaved and forced to build the Colosseum which the Temple’s gold would finance. Many Christians would one day be fed to lions in that very Colosseum.\\nOnce the Temple was destroyed, the world of the Jews was finished. The end came on August 10th 70 AD. Christ’s prophesies had now been completely fulfilled.\\nThis has been a greatly summarized (and censored) account, taken from the Jewish historian Josephus, who witnessed the siege of Jerusalem firsthand.2 Given the full support of other Roman historical records, the account is universally agreed to be incredibly accurate. Being a devout Jew, there should be no suspicion that Josephus sought to align his historical account with the prophesies of Jesus. Therefore it is remarkable that the events that transpired matched Christ’s words perfectly.\\nIt is important to note that the history of the world does not record a parallel instance of unnatural barbarity ever occurring during the siege of any other place in any age or nation whatsoever.\\nOver one million Jews died between 66 and 70 AD. Strikingly, history does not record even one Christian dying in the siege of Jerusalem. History records a massive amount of Christians who sought sanctuary in Pella, a place beyond the Jordan in the mountainous country.3 They remembered the warnings of their Messiah and did what he told them to do: flee to the mountains (Matthew 24:16).\\nSurprisingly, the destruction of Jerusalem and the Temple are not often taught in churches. This is unsettling though, as the destruction of Jerusalem was the final removal of the old covenant and the confirmation that the new covenant had fully arrived. All throughout Jesus’ ministry he emphasized this coming destruction. His longest recorded prophetic word, what is covered in part 1 and 2 of these articles, actually came true!\\nAll throughout the New Testament, the early Church was focused on the coming destruction of Jerusalem. It was an integral part of the good news Jesus brought— God was going to clean out his house and fully establish his Kingdom (Luke 21:31). Jesus also claimed that things will never be as bad as they were in 66-70 AD.\\nFor then there will be great distress, unequaled from the beginning of the world until now—and never to be equaled again.\\nWe can have a hopeful view of the future. We can preach the good news of the Gospel.\\nJesus was prophesying the end of the Temple, the end of the Temple age, which would herald the arrival of the Kingdom of God, which is established around a table instead of a temple. God’s presence is now global, not just local.\\nWe don’t have to wait for a Great Tribulation, it’s already happened. Jesus can just come.', 'story': None, 'topic': None, 'theme': None, 'style': None, 'feature': None, 'grammar': None, 'persona': None, 'initial_word_type': None, 'initial_letter': None, 'word_count': None, 'character_count': None, 'num_paragraphs': None, 'avg_word_length': None, 'avg_sentence_length': None, 'flesch_reading_ease': None, 'flesch_kincaid_grade': None, 'dale_chall_readability_score': None, 'num_stories_in_completion': None, 'expected_num_stories_in_completion': None, 'generation_id': None, 'model': None, 'dump': 'CC-MAIN-2020-05', 'file_path': 's3://commoncrawl/crawl-data/CC-MAIN-2020-05/segments/1579251778272.69/warc/CC-MAIN-20200128122813-20200128152813-00202.warc.gz', 'language': 'en', 'language_score': 0.9736787676811218, 'token_count': 2090, 'score': 2.84375, 'int_score': 3}\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "combined_train_dataset = concatenate_datasets([  \n",
    "    wiki_en,\n",
    "    stories,\n",
    "    fineweb_edu,\n",
    "    owt2,  \n",
    "])  \n",
    "\n",
    "combined_finetune_dataset = concatenate_datasets([\n",
    "    q_a1,\n",
    "    reddit_instruct,\n",
    "    alpaca,\n",
    "])\n",
    "\n",
    "# Shuffle the combined dataset\n",
    "train_dataset = combined_train_dataset.shuffle(seed=42)\n",
    "finetune_dataset = combined_finetune_dataset.shuffle(seed=42)\n",
    "print(f\"Train dataset size: {len(combined_train_dataset)}\")\n",
    "print(f\"Finetune dataset size: {len(combined_finetune_dataset)}\")\n",
    "\n",
    "# Exemple \n",
    "\n",
    "print(\"Example entry from train dataset:\")\n",
    "index = random.randint(0, len(train_dataset)-1)\n",
    "print(train_dataset[index])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Dataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by the dataloader from the \"LLMs from scratch\" repository. But adapted for multi-row text arrays.\n",
    "\n",
    "https://github.com/rasbt/LLMs-from-scratch/blob/main/ch02/01_main-chapter-code/dataloader.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer, max_length):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset: Dataset of the combined hugginface entries\n",
    "            tokenizer: the initiatokenizer to process text\n",
    "            max_length: Context window size\n",
    "        \"\"\"\n",
    "        self.data = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.input_tokens = []\n",
    "        self.target_tokens = []\n",
    "\n",
    "        self.pad_token_id = 50259         # <|pad|>\n",
    "        self.bos_token_id = 50257    # <|im_start|>\n",
    "        self.eos_token_id = 50258    # <|im_end|>\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Raw text\n",
    "        \n",
    "        # Data format handling\n",
    "        entry = self.data[idx]\n",
    "        if 'text' in entry:\n",
    "            text = entry['text']\n",
    "        elif 'story' in entry:\n",
    "            text = entry['story']\n",
    "        elif 'question' in entry and 'answer' in entry: \n",
    "            text = \"User: \" + entry['question'] + \" Assistant:\" + entry['answer']\n",
    "        elif 'post_title' in entry and 'post_text' in entry and 'comment_text' in entry:\n",
    "            text = \"User: \" + entry['post_title'] + \" Assistant:\" + entry['post_text'] + \" \" + entry['comment_text']\n",
    "        elif 'instruction' in entry and 'output' in entry:\n",
    "            text = \"User: \" + entry['instruction'] + \" Assistant:\" + entry['output']\n",
    "        else:\n",
    "            raise ValueError(\"Unknown data entry format\")\n",
    "        \n",
    "        text = str(text) # Ensure text is a string\n",
    "        #print(text)\n",
    "\n",
    "        # Adding Start and End tokens\n",
    "        text = \"<|im_start|>\" + text + \"<|im_end|>\" \n",
    "\n",
    "        # Tokenization\n",
    "        tokens = self.tokenizer.encode(text, allowed_special=\"all\")\n",
    "\n",
    "        # Truncation\n",
    "        tokens = tokens[:self.max_length] #Data is loost here ( fix later with sliding window )\n",
    "\n",
    "        input_ids = torch.tensor(tokens[:-1], dtype=torch.long)  # All tokens except last\n",
    "        labels = torch.tensor(tokens[1:], dtype=torch.long)      # All tokens except first\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        attention_mask = (input_ids != self.pad_token_id).long() # 1 for real tokens, 0 for padding\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTstreamingDataset(IterableDataset):\n",
    "    def __init__(self, dataset, tokenizer, max_length):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset: Dataset of the combined hugginface entries\n",
    "            tokenizer: the initiatokenizer to process text\n",
    "            max_length: Context window size\n",
    "        \"\"\"\n",
    "        self.data = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.bos_token_id = 50257    # <|im_start|>\n",
    "        self.eos_token_id = 50258    # <|im_end|>\n",
    "\n",
    "    def __iter__(self):\n",
    "        buffer = []\n",
    "        for entry in self.data:\n",
    "            # Data format \n",
    "            if entry.get('text') is not None:\n",
    "                text = entry['text']\n",
    "            elif entry.get('story') is not None:\n",
    "                text = entry['story']\n",
    "            elif entry.get('question') is not None and entry.get('answer') is not None: \n",
    "                text = f\"User: {entry['question']} Assistant: {entry['answer']}\"\n",
    "            elif entry.get('post_title') is not None:\n",
    "                title = entry.get('post_title', \"\")\n",
    "                post = entry.get('post_text', \"\")\n",
    "                comment = entry.get('comment_text', \"\")\n",
    "                text = f\"User: {title} Assistant: {post} {comment}\"\n",
    "            elif entry.get('instruction') is not None and entry.get('output') is not None:\n",
    "                text = f\"User: {entry['instruction']} Assistant: {entry['output']}\"\n",
    "            if text is None:\n",
    "                continue\n",
    "                \n",
    "            text = str(text) \n",
    "\n",
    "            # Start and End tokens\n",
    "            text = \"<|im_start|>\" + text + \"<|im_end|>\" \n",
    "\n",
    "            # Tokenization\n",
    "            tokens = self.tokenizer.encode(text, allowed_special=\"all\")\n",
    "\n",
    "            buffer.extend(tokens) #pile tokens into buffer\n",
    "\n",
    "\n",
    "            while len(buffer) >= self.max_length +1:\n",
    "                chunk = buffer[:self.max_length + 1]\n",
    "                buffer = buffer[self.max_length+ 1:] # remove used tokens\n",
    "\n",
    "                input_ids = torch.tensor(chunk[:-1], dtype=torch.long)  \n",
    "                labels = torch.tensor(chunk[1:], dtype=torch.long)      \n",
    "\n",
    "                yield {\n",
    "                    'input_ids': input_ids,\n",
    "                    'labels': labels\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT config "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the configuration for the GPT model i am going to train. It is a smaller version of the GPT-2 model. \n",
    "\n",
    "- Context length: 512 tokens\n",
    "- Embedding dimension: 512\n",
    "- Number of attention heads: 8\n",
    "- Number of layers: 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG = {\n",
    "    \"vocab_size\": 50260,\n",
    "    \"context_length\": 256, # max i could fit on my gpu\n",
    "    \"emb_dim\": 384,\n",
    "    \"number_heads\": 6,\n",
    "    \"number_layers\": 6,\n",
    "    \"drop_rate\": 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test of a entry from dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty cuda cache and memory management\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "train_dataset = GPTstreamingDataset(train_dataset, tokenizer, GPT_CONFIG['context_length'])\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=6, pin_memory=True, prefetch_factor=2, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Test of a entry from dataloader\n",
      "{'input_ids': tensor([[50257,   818,   257,  ...,  4403,  5866, 10062],\n",
      "        [  290,  7103, 28717,  ..., 23312, 33408,   341],\n",
      "        [  262,  4403,  5866,  ..., 24337,  1080,   373],\n",
      "        ...,\n",
      "        [  897,   276,  4034,  ...,  7184,   290,   262],\n",
      "        [  286,  3292,    13,  ...,   991,  9389,  1917],\n",
      "        [ 4525,  4890,    11,  ...,   284,  2074, 48837]]), 'labels': tensor([[  818,   257,  6016,  ...,  5866, 10062,  2838],\n",
      "        [ 7103, 28717,  1989,  ..., 33408,   341,   287],\n",
      "        [ 4403,  5866, 10062,  ...,  1080,   373,   973],\n",
      "        ...,\n",
      "        [  276,  4034,    13,  ...,   290,   262,  5236],\n",
      "        [ 3292,    13,   198,  ...,  9389,  1917,    13],\n",
      "        [ 4890,    11,  8098,  ...,  2074, 48837, 14317]])}\n"
     ]
    }
   ],
   "source": [
    "print(\"##### Test of a entry from dataloader\")\n",
    "batch = next(iter(train_dataloader))\n",
    "print(batch)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytroch model implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this first implementation, i am using the transformer and embedding modules from PyTorch. Later i will try to implement the attention mechanism from scratch for better understanding.\n",
    "\n",
    "https://docs.pytorch.org/docs/stable/generated/torch.nn.Transformer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Gpt model class using transformer library\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        # Network components \n",
    "        ## Embedding layers\n",
    "        self.embedding = nn.Embedding(config['vocab_size'], config['emb_dim'])\n",
    "        self.positional_encoding = nn.Embedding(config['context_length'], config['emb_dim'])\n",
    "        ## Transformer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=config['emb_dim'],\n",
    "            nhead=config['number_heads'],\n",
    "            dim_feedforward=4 * config['emb_dim'],\n",
    "            dropout=config['drop_rate'],\n",
    "            activation='gelu',\n",
    "            batch_first=True,\n",
    "            norm_first=True # stabilityy \n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=config['number_layers'])\n",
    "        ## Output layer\n",
    "        self.output_layer = nn.Linear(config['emb_dim'], config['vocab_size'], bias=False)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.01)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.01)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, label_ids=None):   \n",
    "        batch_size, seq_length = input_ids.shape\n",
    "\n",
    "        # Embedding\n",
    "        token_embeddings = self.embedding(input_ids)  \n",
    "        pos_ids = torch.arange(seq_length, device=input_ids.device).unsqueeze(0)\n",
    "\n",
    "        position_embeddings = self.positional_encoding(pos_ids)  # (batch_size, seq_length, emb_dim)\n",
    "\n",
    "        embeddings = token_embeddings + position_embeddings  # (batch_size, seq_length, emb_dim)\n",
    "\n",
    "        # Prevent attending to future tokens\n",
    "        causal_mask = torch.triu(torch.full((seq_length, seq_length), float('-inf'), device=input_ids.device), diagonal=1)\n",
    "\n",
    "        # voiding to pay attatention padding tokens\n",
    "        key_padding_mask = (attention_mask == 0) if attention_mask is not None else None\n",
    "        \n",
    "        x = self.transformer(embeddings, mask=causal_mask, src_key_padding_mask=key_padding_mask, is_causal=True)\n",
    "        logits = self.output_layer(x)\n",
    "\n",
    "        # Computing loss \n",
    "        if label_ids is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "            loss = loss_fct(logits.view(-1, self.config['vocab_size']), label_ids.view(-1)) # Applies loss to predictions\n",
    "            return logits, loss\n",
    "\n",
    "        return logits, None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModelNoPad(nn.Module):\n",
    "    \"\"\"\n",
    "    Gpt model class using transformer library adapted for streaming dataset without padding mask\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        # Network components \n",
    "        ## Embedding layers\n",
    "        self.embedding = nn.Embedding(config['vocab_size'], config['emb_dim'])\n",
    "        self.positional_encoding = nn.Embedding(config['context_length'], config['emb_dim'])\n",
    "        ## Transformer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=config['emb_dim'],\n",
    "            nhead=config['number_heads'],\n",
    "            dim_feedforward=4 * config['emb_dim'],\n",
    "            dropout=config['drop_rate'],\n",
    "            activation='gelu',\n",
    "            batch_first=True,\n",
    "            norm_first=True # stabilityy \n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=config['number_layers'])\n",
    "        ## Output layer\n",
    "        self.output_layer = nn.Linear(config['emb_dim'], config['vocab_size'], bias=False)\n",
    "        # Weight Tying ( input and output embeddings share weights)\n",
    "        self.output_layer.weight = self.embedding.weight\n",
    "\n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, label_ids=None):   \n",
    "        batch_size, seq_length = input_ids.shape\n",
    "\n",
    "        # Embedding\n",
    "        token_embeddings = self.embedding(input_ids)  \n",
    "        pos_ids = torch.arange(seq_length, device=input_ids.device).unsqueeze(0)\n",
    "\n",
    "        position_embeddings = self.positional_encoding(pos_ids)  # (batch_size, seq_length, emb_dim)\n",
    "\n",
    "        embeddings = token_embeddings + position_embeddings  # (batch_size, seq_length, emb_dim)\n",
    "\n",
    "        # Prevent attending to future tokens\n",
    "        causal_mask = torch.triu(torch.full((seq_length, seq_length), float('-inf'), device=input_ids.device), diagonal=1)\n",
    "        \n",
    "        x = self.transformer(embeddings, mask=causal_mask, is_causal=True)\n",
    "        logits = self.output_layer(x)\n",
    "\n",
    "        # Computing loss \n",
    "        if label_ids is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.config['vocab_size']), label_ids.view(-1)) # Applies loss to predictions\n",
    "            return logits, loss\n",
    "\n",
    "        return logits, None \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model instantiation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rob/micromamba/envs/mlenv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModelNoPad(\n",
      "  (embedding): Embedding(50260, 384)\n",
      "  (positional_encoding): Embedding(256, 384)\n",
      "  (transformer): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (output_layer): Linear(in_features=384, out_features=50260, bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_91822/2518131499.py:7: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()  # Gradient scaler for mixed precision\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GPTModelNoPad(GPT_CONFIG).to(device)\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.1, total_iters=10000) # Linear learning rate scheduler\n",
    "scaler = torch.cuda.amp.GradScaler()  # Gradient scaler for mixed precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of parameters calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 30044928\n"
     ]
    }
   ],
   "source": [
    "# Calculate number of parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)    \n",
    "\n",
    "count_params = count_parameters(model)  \n",
    "print(f\"Number of trainable parameters: {count_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, tokenizer, prompt, max_length=256, device='cpu'):\n",
    "    model.eval()\n",
    "    input_ids = tokenizer.encode(prompt, allowed_special=\"all\")\n",
    "    input_ids = torch.tensor(input_ids, dtype=torch.long).unsqueeze(0).to(device)  # (1, seq_length)\n",
    "\n",
    "    generated_ids = input_ids\n",
    "    max_length = max_length - input_ids.shape[1]  # Remaining length for generation\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            #attention_mask = torch.ones_like(generated_ids)  # All tokens are real (no padding)\n",
    "            logits, _ = model(generated_ids) # model(generated_ids, attention_mask)\n",
    "            next_token_logits = logits[:, -1, :]  #next_token_id = torch.argmax(next_token_logits, dim=-1).unsqueeze(0)  # (1, 1) #\n",
    "            probs = torch.softmax(next_token_logits, dim=-1)\n",
    "            #print(next_token_logits)\n",
    "            next_token_id = torch.multinomial(probs, num_samples=1)  # mult\n",
    "            generated_ids = torch.cat([generated_ids, next_token_id], dim=-1)  # Append to sequence\n",
    "\n",
    "            if next_token_id.item() == 50258:  # Stop if eot token is generated\n",
    "                break\n",
    "\n",
    "    generated_text = tokenizer.decode(generated_ids.squeeze().tolist())\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulation_steps= 1  # Number of steps to accumulate gradients\n",
    "\n",
    "def train_loop(model, dataloader, optimizer, scheduler, device, num_epochs=3, accumulation_steps = 4, question_interval=500, saving_interval=5000):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        step_count = 0\n",
    "\n",
    "        for i, batch in enumerate(progress_bar):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            #attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with torch.amp.autocast('cuda', dtype=torch.bfloat16):  # bf16 optimized for ampere archi\n",
    "                logits, loss = model(input_ids, labels) # model(input_ids, attention_mask, labels)\n",
    "                loss = loss / accumulation_steps\n",
    "            scaler.scale(loss).backward()\n",
    "            if (i + 1) % accumulation_steps == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss += loss.item()*accumulation_steps\n",
    "            progress_bar.set_postfix(loss=loss.item() * accumulation_steps)\n",
    "\n",
    "            # Inference check\n",
    "            step_count += 1\n",
    "            if step_count % question_interval == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    prompt = \"AI is technology that enables computers and machines to\"\n",
    "                    generated_text = inference(model, tokenizer, prompt, max_length=50, device=device)\n",
    "                    print(f\"\\n[Inference at step {step_count}]\")\n",
    "                    #save generated text to file train_ouput.txt\n",
    "                    with open(\"outputs/train_output.txt\", \"a\") as f:\n",
    "                        if generated_text.strip() != \"\":\n",
    "                            f.write(f\"\\n[Inference at step {step_count}]: {generated_text}\\n\")  \n",
    "                            f.write(\"-\"*50 + \"\\n\")\n",
    "                        else:\n",
    "                            f.write(f\"\\n[Inference at step {step_count}]: [No output generated]\\n\")\n",
    "                            f.write(\"-\"*50 + \"\\n\")\n",
    "                model.train()\n",
    "\n",
    "            if step_count % saving_interval == 0:\n",
    "                # Save model checkpoint\n",
    "                date = datetime.now().strftime(\"%Y%m%d\")\n",
    "                # Create models directory if it doesn't exist\n",
    "                Path(f\"models/{date}\").mkdir(parents=True, exist_ok=True)\n",
    "                checkpoint_path = f\"models/{date}/weights_step{step_count}.pt\"\n",
    "                torch.save(model.state_dict(), checkpoint_path)\n",
    "                print(f\"\\nModel checkpoint saved at step {step_count} to {checkpoint_path}\")\n",
    "\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1} completed. Average Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_weights(model, checkpoint_path, device):\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    model.to(device)\n",
    "    print(f\"Model loaded from {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First training on combined train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_91822/4287008090.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from models/starter/weights_step10000.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 15it [00:02,  5.72it/s, loss=5.82]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m torch.cuda.synchronize()\n\u001b[32m      5\u001b[39m load_model_weights(model, \u001b[33m\"\u001b[39m\u001b[33mmodels/starter/weights_step10000.pt\u001b[39m\u001b[33m\"\u001b[39m, device)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mtrain_loop\u001b[39m\u001b[34m(model, dataloader, optimizer, scheduler, device, num_epochs, accumulation_steps, question_interval, saving_interval)\u001b[39m\n\u001b[32m     19\u001b[39m scaler.scale(loss).backward()\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (i + \u001b[32m1\u001b[39m) % accumulation_steps == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     scaler.update()\n\u001b[32m     23\u001b[39m     optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/mlenv/lib/python3.11/site-packages/torch/amp/grad_scaler.py:454\u001b[39m, in \u001b[36mGradScaler.step\u001b[39m\u001b[34m(self, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    448\u001b[39m     \u001b[38;5;28mself\u001b[39m.unscale_(optimizer)\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m    451\u001b[39m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m]) > \u001b[32m0\u001b[39m\n\u001b[32m    452\u001b[39m ), \u001b[33m\"\u001b[39m\u001b[33mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m retval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    456\u001b[39m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m] = OptState.STEPPED\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/mlenv/lib/python3.11/site-packages/torch/amp/grad_scaler.py:351\u001b[39m, in \u001b[36mGradScaler._maybe_opt_step\u001b[39m\u001b[34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    344\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    345\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    348\u001b[39m     **kwargs: Any,\n\u001b[32m    349\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    350\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf_per_device\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    352\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/mlenv/lib/python3.11/site-packages/torch/amp/grad_scaler.py:351\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    344\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    345\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    348\u001b[39m     **kwargs: Any,\n\u001b[32m    349\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    350\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    352\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#empty gpu memory \n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "load_model_weights(model, \"models/starter/weights_step10000.pt\", device)\n",
    "\n",
    "train_loop(model, train_dataloader, optimizer, scheduler, device, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources \n",
    "\n",
    "### Principal references: \n",
    "- https://arxiv.org/abs/2005.14165 (GPT-3 paper)\n",
    "- https://arxiv.org/abs/2002.05709 (Attention is all you need paper)\n",
    "- Build a Large Language Model (from scratch) by Sebastian Raschka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
